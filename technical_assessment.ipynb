{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf pytesseract sentence-transformers faiss-cpu transformers pillow -q\n",
        "!apt-get update && apt-get install -y tesseract-ocr tesseract-ocr-ben -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVmlHtzZc0iZ",
        "outputId": "e8b103c8-98ed-4d48-8d87-d88d2d3704a8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-ben is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5960bb8f",
        "outputId": "f5dc88f1-b25d-416c-d28c-4b1f922f44da"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok, conf\n",
        "import uvicorn\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "rCPHEAz42aHe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "Xg-RjX7L2oM6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "try:\n",
        "    embedding_model = SentenceTransformer('l3cube-pune/bengali-sentence-similarity-sbert')\n",
        "    tokenizer_hf = AutoTokenizer.from_pretrained('csebuetnlp/banglat5')\n",
        "    model_hf = AutoModelForSeq2SeqLM.from_pretrained('csebuetnlp/banglat5')\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to initialize models: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "wzrnbEHz2u2q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "chunks = []\n",
        "index = None\n",
        "embeddings = None\n",
        "conversation_history = []"
      ],
      "metadata": {
        "id": "xC1Hco0IEHux"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Functions\n",
        "def preprocess_image(img):\n",
        "    \"\"\"Preprocess image for better OCR results.\"\"\"\n",
        "    try:\n",
        "        # Convert to grayscale\n",
        "        img = img.convert('L')\n",
        "        # Enhance contrast\n",
        "        enhancer = ImageEnhance.Contrast(img)\n",
        "        img = enhancer.enhance(2.5)\n",
        "        # Sharpen image\n",
        "        img = img.filter(ImageFilter.SHARPEN)\n",
        "        # Resize for higher resolution\n",
        "        img = img.resize((int(img.width * 2.5), int(img.height * 2.5)), Image.Resampling.LANCZOS)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error preprocessing image: {e}\")\n",
        "        return img"
      ],
      "metadata": {
        "id": "7q5Br5NIeor_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Clean extracted text to remove noise and normalize Bangla characters.\"\"\"\n",
        "    try:\n",
        "        # Normalize Unicode\n",
        "        text = unicodedata.normalize('NFKC', text)\n",
        "        # Keep only Bangla characters, punctuation, and whitespace\n",
        "        text = re.sub(r'[^\\u0980-\\u09FF।!?\\s\\n\\d]', '', text)\n",
        "        # Remove stray vowel signs and invalid sequences\n",
        "        text = re.sub(r'[\\u09BE-\\u09CC\\u09D7]+(?![া-ঢ়য়-৺])', '', text)\n",
        "        # Normalize spaces and newlines\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\n+', '\\n', text).strip()\n",
        "        # Filter short lines (likely noise)\n",
        "        lines = [line for line in text.split('\\n') if len(line.strip()) > 10]\n",
        "        return '\\n'.join(lines)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error cleaning text: {e}\")\n",
        "        return text"
      ],
      "metadata": {
        "id": "z0KTnTPker7l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from PDF with enhanced OCR and cleaning.\"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            page_text = page.get_text()\n",
        "            if len(page_text.strip()) < 50:  # Likely a scanned page\n",
        "                pix = page.get_pixmap(dpi=400)\n",
        "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.rgb)\n",
        "                img = preprocess_image(img)\n",
        "                page_text = pytesseract.image_to_string(img, lang='ben', config='--psm 6 --oem 3')\n",
        "            text += clean_text(page_text) + \"\\n\"\n",
        "        doc.close()\n",
        "        # Save extracted text for debugging\n",
        "        with open('extracted_text.txt', 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "        # Check text quality\n",
        "        bangla_chars = len(re.findall(r'[\\u0980-\\u09FF]', text))\n",
        "        total_chars = len(text.replace('\\n', ''))\n",
        "        if total_chars > 0 and bangla_chars / total_chars < 0.6:\n",
        "            logger.warning(\"Extracted text may be noisy; Bangla character ratio low: {:.2f}\".format(bangla_chars / total_chars))\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error extracting text from PDF: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "aq21ltyne3UV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_tokens=200):\n",
        "    \"\"\"Chunk text into question-answer pairs or sentences, handling noisy text.\"\"\"\n",
        "    chunks = []\n",
        "    question_pattern = r'(\\d+\\.\\s*.*?[।!?])\\s*(ক\\s*.*?|খ\\s*.*?|গ\\s*.*?|ঘ\\s*.*?(?=\\d+\\.|$))'\n",
        "    matches = re.finditer(question_pattern, text, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "    for match in matches:\n",
        "        qa_pair = match.group(0).strip()\n",
        "        token_count = len(qa_pair.split())\n",
        "        if token_count <= max_tokens:\n",
        "            chunks.append(qa_pair)\n",
        "        else:\n",
        "            sentences = re.split(r'(?<=[।!?\\.])\\s+', qa_pair)\n",
        "            sub_chunk = \"\"\n",
        "            sub_tokens = 0\n",
        "            for sentence in sentences:\n",
        "                sentence = sentence.strip()\n",
        "                if not sentence or len(sentence) < 10:\n",
        "                    continue\n",
        "                sentence_tokens = len(sentence.split())\n",
        "                if sub_tokens + sentence_tokens <= max_tokens:\n",
        "                    sub_chunk += \" \" + sentence\n",
        "                    sub_tokens += sentence_tokens\n",
        "                else:\n",
        "                    if sub_chunk:\n",
        "                        chunks.append(sub_chunk.strip())\n",
        "                    sub_chunk = sentence\n",
        "                    sub_tokens = sentence_tokens\n",
        "            if sub_chunk:\n",
        "                chunks.append(sub_chunk.strip())\n",
        "\n",
        "    remaining_text = re.sub(question_pattern, '', text, flags=re.DOTALL | re.IGNORECASE)\n",
        "    sentences = re.split(r'(?<=[।!?\\.])\\s+', remaining_text)\n",
        "    current_chunk = \"\"\n",
        "    current_tokens = 0\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if not sentence or len(sentence) < 10:\n",
        "            continue\n",
        "        sentence_tokens = len(sentence.split())\n",
        "        if current_tokens + sentence_tokens <= max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_tokens += sentence_tokens\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_tokens = sentence_tokens\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return [chunk for chunk in chunks if chunk and len(chunk.strip()) > 15]"
      ],
      "metadata": {
        "id": "__PoSWf43Alg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_query(query):\n",
        "    \"\"\"Normalize and clean the query text.\"\"\"\n",
        "    query = unicodedata.normalize('NFKC', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    return query"
      ],
      "metadata": {
        "id": "UGrX_NFyFH9I"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_from_context(context, question):\n",
        "    \"\"\"Generate an answer with strict option selection.\"\"\"\n",
        "    try:\n",
        "        prompt = (\n",
        "            f\"প্রশ্ন: {question}\\n\"\n",
        "            f\"প্রসঙ্গ: {context}\\n\"\n",
        "            f\"উত্তর: শুধুমাত্র সঠিক বিকল্পটি নির্বাচন করুন (যেমন ক, খ, গ, ঘ) এবং বিকল্পের পাঠ্য। \"\n",
        "            f\"অন্য কোনো পাঠ্য যোগ করবেন না।\"\n",
        "        )\n",
        "        inputs = tokenizer_hf(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "        outputs = model_hf.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            num_beams=5,\n",
        "            no_repeat_ngram_size=2,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        answer = tokenizer_hf.decode(outputs[0], skip_special_tokens=True)\n",
        "        return answer.strip()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating answer: {e}\")\n",
        "        return \"Error generating answer.\""
      ],
      "metadata": {
        "id": "vWe47Rkh4iZY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_pdf(pdf_path):\n",
        "    \"\"\"Process a PDF to update global chunks, index, and embeddings.\"\"\"\n",
        "    global chunks, index, embeddings\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    if not text:\n",
        "        logger.error(\"No text extracted from PDF.\")\n",
        "        return False\n",
        "\n",
        "    chunks = chunk_text(text, max_tokens=200)\n",
        "    if not chunks:\n",
        "        logger.error(\"No chunks created from text.\")\n",
        "        return False\n",
        "\n",
        "    embeddings = embedding_model.encode(chunks)\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings.astype(\"float32\"))\n",
        "    logger.info(f\"Processed PDF: {pdf_path}, created {len(chunks)} chunks\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "rxl8qjTHfVbv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_and_answer(query, chunks, index, embeddings, top_k=10, threshold=0.3):\n",
        "    \"\"\"Retrieve relevant chunks and generate an answer.\"\"\"\n",
        "    global conversation_history\n",
        "    try:\n",
        "        if not chunks or index is None or embeddings is None:\n",
        "            logger.warning(\"No PDF data available.\")\n",
        "            return \"No PDF data available.\", \"\"\n",
        "\n",
        "        query = preprocess_query(query)\n",
        "        query_vec = embedding_model.encode([query]).astype(\"float32\")\n",
        "        distances, indices = index.search(query_vec, top_k)\n",
        "\n",
        "        if min(distances[0]) > threshold:\n",
        "            logger.warning(\"No relevant context found.\")\n",
        "            return \"Query is too vague or no relevant information found.\", \"\"\n",
        "\n",
        "        context = \"\\n\".join([chunks[i] for i in indices[0] if re.search(r'[\\u0980-\\u09FF]', chunks[i])])\n",
        "        if not context:\n",
        "            logger.warning(\"No valid Bangla context found.\")\n",
        "            return \"No valid context found.\", \"\"\n",
        "\n",
        "        answer = generate_answer_from_context(context, query)\n",
        "        conversation_history.append({\n",
        "            \"query\": query,\n",
        "            \"answer\": answer,\n",
        "            \"context\": context[:300],\n",
        "            \"grounded\": evaluate_groundedness(answer, context)\n",
        "        })\n",
        "        return answer, context\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in retrieve_and_answer: {e}\")\n",
        "        return \"Error processing query.\", str(e)"
      ],
      "metadata": {
        "id": "KXR59SSQ4rDR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Upload PDF\n",
        "print(\"Please upload HSC26-Bangla1st-Paper.pdf\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# ## Specific Test Cases\n",
        "# Define test cases\n",
        "test_cases = [\n",
        "    {\"query\": \"অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\", \"expected_answer\": \"শুম্ভুনাথ\"},\n",
        "    {\"query\": \"কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?\", \"expected_answer\": \"মামাকে\"},\n",
        "    {\"query\": \"বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\", \"expected_answer\": \"১৫ বছর\"}\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "moQ0kNPSgWKG",
        "outputId": "4a0c3054-4305-4a7b-eaf2-07e372bfab23"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload HSC26-Bangla1st-Paper.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99b544d7-8353-4dd5-a787-b2b3fc49e9f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99b544d7-8353-4dd5-a787-b2b3fc49e9f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HSC26-Bangla1st-Paper.pdf to HSC26-Bangla1st-Paper.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the PDF\n",
        "success = process_pdf(\"/content/HSC26-Bangla1st-Paper.pdf\")\n",
        "if not success:\n",
        "    print(\"Failed to process PDF. Check logs and 'extracted_text.txt' for details.\")\n",
        "else:\n",
        "    print(f\"PDF processed successfully: {len(chunks)} chunks created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja46fi5KhEsu",
        "outputId": "71cf5649-f505-4c8e-deff-314ecd041c47"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF processed successfully: 35 chunks created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests\n",
        "for test in test_cases:\n",
        "    query = test[\"query\"]\n",
        "    expected_answer = test[\"expected_answer\"]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Query: {query}\")\n",
        "    answer, context = retrieve_and_answer(query, chunks, index, embeddings, top_k=10, threshold=0.3)\n",
        "    grounded = evaluate_groundedness(answer, context)\n",
        "\n",
        "    # Check if the answer matches the expected answer\n",
        "    pass_match = expected_answer in answer\n",
        "    status = \"Passed\" if pass_match else \"Failed\"\n",
        "\n",
        "    print(f\"Generated Answer: {answer}\")\n",
        "    print(f\"Expected Answer: {expected_answer}\")\n",
        "    print(f\"Context (truncated): {context[:300]}...\")\n",
        "    print(f\"Grounded: {grounded}\")\n",
        "    print(f\"Status: {status}\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy1mA2_V4xlc",
        "outputId": "b4844e6f-5d17-49c2-a1b5-7f7efa1a9327"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Query: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n",
            "Generated Answer: পপব্সকহব? ক খ গ ণযববববব গ কব ক গ গ ৩৮। ক কখখগ কগ গ ম গ ন গবগ\n",
            "Expected Answer: শুম্ভুনাথ\n",
            "Context (truncated): ক অনপকম মম খ অনপকম ম গ ম্ভনথ ব্ব্ ঘ হর্ উ গ ৩৩। র্র্কনসকথকলযণর্মলযকথ ? উভ ইর্জক্ষত উভ ইর্জক্ষত ব্ব্আজ্ঞব্হ র্নকচ যকনট সঠক? ক খ গ ঘ উ ক র্নকচউদ্দপকটপক়ে৩৪ও৩৫নম্বপ্রকউদও স্বতসর্জক্ষতওআত্মর্নভলন।র্ব্ক পশ্বশওশর়্চকপচকর়্কতব্ধযহ ।শ্বশ শর়্ধণচকর্ব্ব্উঅহংকহ ।তসংসকপ্রর্তদর্ ত্বলন ।য দ ১৯ ৩৪। অপর্র্চত গকসকঙ্...\n",
            "Grounded: False\n",
            "Status: Failed\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Query: কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?\n",
            "Generated Answer: ণ কণক কগ ক গ খ খ গ গ ঘ ৪৩ গ ৪৯ ক খ ৪২ গ ৫৩ গ ৪৬ খ ৪৯ গ ৪৭ ক ৪২ ক ৪৩ ক ৪১ ক ৪৯ খ ক্্্ কক্ ক্\n",
            "Expected Answer: মামাকে\n",
            "Context (truncated): ক খ গ ঘ\n",
            "উমল ১ ক ২ খ ৩ ক ৪ গ ৫ ক ৬ গ ৭ ক ৮ খ ৯ খ ১০ খ ১১ খ ১২ ক ১৩ গ ১৪ খ ১৫ গ ১৬ গ ১৭ খ ১৮ খ ১৯ গ ২০ ঘ ২১ ঘ ২২ ক ২৩ ঘ ২৪ ক ২৫ ঘ ২৬ খ ২৭ ক ২৮ ক ২৯ গ ৩০ ক ৩১ গ ৩২ খ ৩৩ খ ৩৪ ক ৩৫ ঘ ৩৬ খ ৩৭ ক ৩৮ গ ৩৯ গ ৪০ খ ৪১ গ ৪২ ক ৪৩ ক ৪৪ গ ৪৫ খ ৪৬ খ ৪৭ খ ৪৮ খ ৪৯ খ ৫০ খ ৫১ ঘ ৫২ গ ৫৩ গ ৫৪ খ ৫৫ খ ৫৬ খ ৫৭ গ ৫৮ ক ৫৯ ক ৬০...\n",
            "Grounded: False\n",
            "Status: Failed\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Query: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\n",
            "Generated Answer: ক্ কক্ খ গ গ ঘ ণ ক খ খ ঙ গ খ কগ কখগ ঘ গ কফ ক ফ গ র্গ ঘ ঘ ন ক্ কক্খ্ খক্ ককখক ক\n",
            "Expected Answer: ১৫ বছর\n",
            "Context (truncated): ক খ গ ঘ\n",
            "উমল ১ ক ২ খ ৩ ক ৪ গ ৫ ক ৬ গ ৭ ক ৮ খ ৯ খ ১০ খ ১১ খ ১২ ক ১৩ গ ১৪ খ ১৫ গ ১৬ গ ১৭ খ ১৮ খ ১৯ গ ২০ ঘ ২১ ঘ ২২ ক ২৩ ঘ ২৪ ক ২৫ ঘ ২৬ খ ২৭ ক ২৮ ক ২৯ গ ৩০ ক ৩১ গ ৩২ খ ৩৩ খ ৩৪ ক ৩৫ ঘ ৩৬ খ ৩৭ ক ৩৮ গ ৩৯ গ ৪০ খ ৪১ গ ৪২ ক ৪৩ ক ৪৪ গ ৪৫ খ ৪৬ খ ৪৭ খ ৪৮ খ ৪৯ খ ৫০ খ ৫১ ঘ ৫২ গ ৫৩ গ ৫৪ খ ৫৫ খ ৫৬ খ ৫৭ গ ৫৮ ক ৫৯ ক ৬০...\n",
            "Grounded: False\n",
            "Status: Failed\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Debugging Output\n",
        "# Display first 1000 characters of extracted text for inspection\n",
        "with open('extracted_text.txt', 'r', encoding='utf-8') as f:\n",
        "    extracted_text = f.read()\n",
        "print(\"\\nExtracted Text (first 1000 characters):\\n\")\n",
        "print(extracted_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJOzkEDsfjPp",
        "outputId": "926542da-cb70-41c7-ed4a-64f983631b6f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted Text (first 1000 characters):\n",
            "\n",
            "অনলইন ব্যচ সম্পর্কত যকককন জজ্ঞস অপররত আল য রষয় ং ১ম পত্র\n",
            "১। অনপল ক কল জরক রনবহ কলতন? ক ডক্তর্ খ ওকলর্ত গ মস্টর্ ঘ ব্যব্স ২। লক ভগ্য দত প্রধন এলজন্ট কণ ত ক প্রর্তপজ খ প্রভব্ গ র্ব্চক্ষণত ঘ কট ব্র্ র্নকচ অনকদট পক় ৩ ও ৪ সংখযক প্রক উ দও। র্পতহন দপ চচই র্কলন পর্ব্ক কত। দপ র্জক্ষত হকলও ত র্সন্ত যনও ক্ষমত র্ল ন। চচ ত র্ব্ক উকদযগ র্নকলও যতক র্নক ব়্ব্র়্ ক ককণ কনয র্পত অপমর্নত যব্ধ কক র্ব্ক আকলচন যভক যদন। দপ যমক ট র্ব্ যদকখ মগ্ধ হকলও ত চচকক র্কই ব্লকত পকনর্ন। ৩। প সল অপররত গ্ল দকন রল র আল? ক হর্ক খ মম গ র্ক্ষকক ঘ র্ব্ন ৪। উক্ত রল প্রধনয দপলয়ল যদত্ম হনম্মনযত যলভ র্নকচ যকনট ঠক? ক। ও খ। ও গ। ও ঘ। ও ৫ অনপল য়স কত ? ক পঁর্চ খ ব্ব গ সত ঘ আট প্রকমলয ন কতগকল প্রক সঠক উ র্দকত পকল? ১ খ ২ গ ৩ খ ৪ ক ৫ গ র্নম্নর্ব্ব্যজক্তহঠাৎর্ব্লহক ওঠফকলসমকপর্চ সংকটসম্পককধণলভককব্। তৎকলনসমসভযতওমনব্তঅব্মননসম্পককনকতপকব্। তৎকলনসমকপণপ্রথকপ্রভব্সম্পককনকতপকব্। তৎককলসমকভদ্রকলককস্বভব্বব্র্ষ্ট্যসম্পককজ্ঞনলভককব্। নযকমলঠক র্কন্তদব্লন কলযণব্নচর্তদ্বপ্রর্তজতএইসতযঅনধব্নককত পকব্। মনষআর্নক যব্ঁকচথকক অনপকমদষ্ট্কন্তমনব্ব্কনএইর্চন্তনসতযদন\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up FastAPI\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/upload-pdf\")\n",
        "async def upload_pdf(file: UploadFile = File(...)):\n",
        "    \"\"\"Upload a PDF file and process it for RAG.\"\"\"\n",
        "    try:\n",
        "        if not file.filename.endswith('.pdf'):\n",
        "            logger.error(\"Uploaded file is not a PDF.\")\n",
        "            return {\"error\": \"Please upload a valid PDF file.\"}\n",
        "\n",
        "        # Save the uploaded file temporarily\n",
        "        temp_file = f\"temp_{file.filename}\"\n",
        "        with open(temp_file, \"wb\") as f:\n",
        "            content = await file.read()\n",
        "            f.write(content)\n",
        "\n",
        "        # Process the PDF\n",
        "        success = process_pdf(temp_file)\n",
        "\n",
        "        # Clean up the temporary file\n",
        "        try:\n",
        "            os.remove(temp_file)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to delete temporary file {temp_file}: {e}\")\n",
        "\n",
        "        if success:\n",
        "            return {\"message\": f\"PDF {file.filename} processed successfully. {len(chunks)} chunks created.\"}\n",
        "        else:\n",
        "            return {\"error\": \"Failed to process PDF.\"}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error uploading PDF: {e}\")\n",
        "        return {\"error\": \"Failed to upload and process PDF.\"}"
      ],
      "metadata": {
        "id": "rJIBXCHW49S9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post(\"/ask\")\n",
        "async def ask_question(query: str):\n",
        "    \"\"\"API endpoint to process queries.\"\"\"\n",
        "    try:\n",
        "        answer, context = retrieve_and_answer(query, chunks, index, embeddings)\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"answer\": answer,\n",
        "            \"context\": context[:300],\n",
        "            \"grounded\": evaluate_groundedness\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"API error: {e}\")\n",
        "        return {\"error\": \"Failed to process query.\"}"
      ],
      "metadata": {
        "id": "acKkfmS249_Y"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the API\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "    try:\n",
        "        ngrok.set_auth_token(\"30PAzjEoyE4OhrNY5oEis32EmpL_XWLYjfSCFn8K4TaocFLD\")\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                public_url = ngrok.connect(8001)\n",
        "                logger.info(f\"Public URL: {ngrok.connect(8000)}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Ngrok connection attempt {attempt + 1} failed: {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(2)\n",
        "                else:\n",
        "                    logger.error(\"Failed to establish ngrok tunnel after retries.\")\n",
        "                    raise\n",
        "\n",
        "        # Start FastAPI server\n",
        "        print(f\"Public URL: {public_url}\")\n",
        "        logger.info(\"Starting FastAPI server on http://localhost:8001\")\n",
        "        uvicorn.run(app, host=\"localhost\", port=8001)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to start API: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7PBbG4mF-VR",
        "outputId": "b9abf243-63ed-4204-ff39-b5458c99be89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://7cd4560022b9.ngrok-free.app\" -> \"http://localhost:8001\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [932]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://localhost:8001 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    }
  ]
}